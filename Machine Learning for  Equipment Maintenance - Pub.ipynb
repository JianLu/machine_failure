{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Machine Learning for Equipment Failure Prediction and Equipment Maintenance (PM)"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "When it comes to dealing with machines that require periodic maintenance, there are generally three possible outcomes.\n\nOne, you can maintain a machine too frequently. In other words, the machine gets maintenance when it is not required. In this scenario, you are throwing money out the window, wasting resources providing unnecessary maintenance. For example, you could change the oil in your car every single day. This is not optimal, and you will waste a lot of money on unnecessary maintenance.\n\nTwo, you don\u2019t maintain your machine frequently enough. Failing to maintain a machine means that the machine will break while operating. Here, the costs could be substantial. Not only do you have the repair costs, but also costs associated with lost production. If a machine on the assembly line goes down, the line cannot produce anything. No production means lost profit. Also, you will incur legal and medical costs if injuries occurred as a result of the failure.\n\nThree, a machine is maintained when it needs maintenance. This is obviously the better alternative of the three. Note, that that there is still a cost associated with timely maintenance.\n\nSo, we need to maintain machines when they need maintenance, right? Unfortunately, this is easier said than done. Fortunately, we can use predictive maintenance (PM) to predict when machines need maintenance.\n\nI should also mention that most machines come with manufacturer recommendations on maintenance. The problem with manufacturer recommendations is that they represent an average. For example, cars on average need an oil change every 3,000 miles, but how frequently does your car need an oil change? It may be more or less than 3,000 miles depending on several factors, including where your drive, how you drive, and how frequently you drive.\n\nPredictive maintenance (PM) can tell you, based on data, when a machine requires maintenance. An effective PM program will minimize under and over maintaining your machine. For a large manufacturer with thousands of machines, being precise on machine maintenance can save millions of dollars every year.\n\nIn this article, I will examine a typical Predictive Maintenance (PM) use case. As I walk through this example, I will describe some of the issues that arise with PM problems and suggest ways to solve them.\n\nAn important note about the data used in this exercise. It is entirely fake. I created the data based on my experience of dealing with these types of problems. Although it is entirely artificial, I believe the data and use case are very realistic and consistent with many real PM problems.\n\n\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The firm in our use case provided a sample of data that includes 419 machines that failed over a two year period. They spent about 11.7M dollars on maintenance, most of which came from running machines until failure.\n\nHere is a summary of the maintained or repaired machines over the last two years."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://miro.medium.com/max/4800/1*5Ar2n3ZHMwVeOhgXI_dm0w.png\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "From the data above, it currently costs the firm about $28,000 per failed or maintained machine. Our goal is to lower this cost.\n\nIn the chart above, Timely Maintenance costs more than Unnecessary Maintenance. There is a good reason for this. For this machine, unnecessary maintenance means that that machine was moved off-line and checked, but the part in question showed insufficient wear to replace. Because parts were not replaced, there are no material costs, only labor.\n\nNote that this company does very little predictive maintenance. Most of the time, they just run the machines to failure. Also, note that these machines will break in four to eight years if they don\u2019t receive maintenance. When they fail, they must be pulled off-line and repaired.\n\nOur goal is to show the firm how a Predictive Maintenance program can save them money. To do this, we will build a predictive model that predicts machine failure within 90 days of actual failure. Note that an appropriate failure window will always depend on the context of the problem. If a machine breaks without maintenance in 6 months, a three-month window makes no sense. Here, where a machine will run between 4 to 6 years without maintenance, a 90-day window is reasonable.\n\nOur objective is to develop a solution that will lower the costs of failure. Again, it currently costs the firm about 28,000 per machine. We will attempt to reduce this cost."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Table of Contents"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "1. [Getting Setup](#setup1)<br>\n \n2. [Data Exploration](#explore)<br>\n\n3. [Data Transformation and Feature Engineering](#trans)<br>\n \n4. [Dealing with the Small Number of Failures](#small)<br>\n    4.1 [Expand the Failure Window](#window)<br>\n    4.2 [Create Testing, Training and Validation Groups](#groups)<br>\n    4.3 [SMOTE the Training Data](#smote)<br>\n5. [More Data Transformations and Feature Engineering](#more)<br>\n6. [Build the Model on the Balanced Data Set](#build)<br>\n7. [Score the Unbalanced Training Data Set](#score)<br>\n8. [Business Rules and Heuristics](#bus)<br>\n9. [Define a True Positive, True Negative, False Positive and False Negative](#tp)<br>\n10. [Apply Model and Heuristics to the Testing and Validation Data Sets](#apply)<br>\n11. [Conclusions](#conc)<br>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 1.0 Getting Set-Up <a id=\"setup1\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " Install all of the relevant Python Libraries"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n!pip install imblearn --upgrade\n!pip install plotly --upgrade\n!pip install chart-studio --upgrade\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Import required libraries"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "import chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport plotly as plotly\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SMOTENC\nfrom sklearn import metrics\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Import the data from GitHub"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_1.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#import first half from github\n!wget https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_1.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Convert csv to pandas dataframe\npd_data_1 = pd.read_csv(\"equipment_failure_data_1.csv\", sep=\",\", header=0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_2.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Import the second half from github\n!wget https://raw.githubusercontent.com/shadgriffin/machine_failure/master/equipment_failure_data_2.csv",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# convert to pandas dataframe\npd_data_2 = pd.read_csv(\"equipment_failure_data_2.csv\", sep=\",\", header=0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#concatenate the two data files into one dataframe\npd_data=pd.concat([pd_data_1, pd_data_2])\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 2.0 Data Exporation <a id=\"explore\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have the data imported into a Jupiter Notebook, we can explore it. Here is metadata explaining all of the fields in the data set.\n\nID \u2014 ID field that represents a specific machine.\n\nDATE \u2014 The date of the observation.\n\nREGION_CLUSTER \u2014 a field that represents the region in which the machine resides.\n\nMAINTENANCE_VENDOR \u2014 a field that represents the company that provides maintenance and service to the machine.\n\nMANUFACTURER \u2014 the company that manufactured the equipment in question.\n\nWELL_GROUP \u2014 a field representing the type of machine.\n\nEQUIPMENT_AGE \u2014 Age of the machine, in days.\n\nS15 \u2014 A Sensor Value.\n\nS17 \u2014 A Sensor Value.\n\nS13 \u2014 A Sensor Value.\n\nS16 \u2014 A Sensor Value.\n\nS19 \u2014 A Sensor Value.\n\nS18 \u2014 A Sensor Value.\n\nS8 \u2014 A Sensor Value.\n\nEQUIPMENT_FAILURE \u2014 A \u20181\u2019 means that the equipment failed. A \u20180\u2019 means the equipment did not fail.\n\nOur first goal in this exercise is to build a model that predicts equipment failure. In other words, we will use the other variables in the data frame to predict EQUIPMENT_FAILURE.\n\nNow we will walk through the data.\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Examine the number of rows and columns.  The data has 307,751 rows and 16 columns"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\npd_data.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "There are 421 machines in the data set"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['ID']).agg(['count']))\nxxxx.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "there are 731 unique dates in the data set"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['DATE']).agg(['count']))\nxxxx.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We have 731 unique dates.  So if we have 421 machines and 731 unique dates, we should have 307,751 total records.  Based on the .shape command, we have one record per machine per date value.  There are no duplicates in the data frame.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "And to triple confirm remove all duplicates and count the rows again."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_failure_thingy=pd_data\ndf_failure_thingy=df_failure_thingy.drop_duplicates(subset=['ID','DATE'])\ndf_failure_thingy.shape\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Look for null values in the fields -- There are none"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data.isnull().sum(axis = 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now let\u2019s examine the dependent variable in more detail. It appears that out of 307,751 records, we only have 421 failures. This corresponds to a failure rate of about .14%. In other words, for every failure, you have over 700 non-failures. This data set is very unbalanced. Later in this article, I will use a few techniques to mitigate the impact of a small number of observed failures."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xxxx = pd.DataFrame(pd_data.groupby(['EQUIPMENT_FAILURE'])['ID'].agg('count'))\nxxxx",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We can also explore the data with descriptive statistics"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\npd_data.describe()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Examine a simple correlation of the independent variable with the dependent variable.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xxx=pd_data.corr( method='pearson')\n\nxxx=xxx[['EQUIPMENT_FAILURE']]\nxxx['ABS_EQUIPMENT_FAILURE']=abs(xxx['EQUIPMENT_FAILURE'])\nxxx=xxx.sort_values(by=['ABS_EQUIPMENT_FAILURE'], ascending=[False])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xxx",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 3.0 Data transformations and Feature Engineering <a id=\"trans\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Next, we can transform our data for a machine learning model. Specifically, we will create running summaries of the sensor values. Running summaries of sensor values are often useful in predicting equipment failure. For example, if a temperature gauge indicates a machine is warmer than average for the last five days, it may mean something is wrong.\n\nRemember that we are working with a panel data set. That is, we have multiple machines measured over two years. As we create our running summaries, we have to make sure that our summaries do not include more than one machine. For example, if we create a ten-day moving average, we do not want the first nine days of a machine to have values from the previous machine.\n\nNote that I create twenty-one-day summaries in this example. This works for this use case, but it may be advantageous to use more or different time intervals for other situations.\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert dates from character to date."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\n\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new field called \u201cflipper\u201d that indicates when the id changes as the data are sorted by ID and DATE in ascending order. We will use this in a few other transformations."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID','DATE'], ascending=[True, True])\n\npd_data['flipper'] = np.where((pd_data.ID != pd_data.ID.shift(1)), 1, 0)\npd_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Running summaries are often useful transformations for these types of a problems.  For example, a running mean would be the average value over the last x days.  X in this case is the feature window.  The feature window is a parameter that depends on the context of the business problem.  I am setting the value to 21 days, but this may or may not work for your business problem."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#define your feature window. This is the window by which we will aggregate our sensor values.\nfeature_window=21",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the number of days from the first day a machine appears to the current day. This field will be called \u201cTIME_SINCE_START\u201d Also, create a variable called \u201ctoo_soon.\u201d When \u201ctoo_soon\u201d is equal to 1, we have less than 21 days (feature_window) of history for the machine.\n\nWe will use these new variables to create a running mean, median, max, and min. \n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dfx=pd_data",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Select the first record of each machine\n\nstarter=dfx[dfx['flipper'] == 1]\n\nstarter=starter[['DATE','ID']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#rename data to start_date\nstarter=starter.rename(index=str, columns={\"DATE\": \"START_DATE\"})",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#convert START_DATE to date\nstarter['START_DATE'] = pd.to_datetime(starter['START_DATE'])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Merge START_DATE to the original data set\n\ndfx=dfx.sort_values(by=['ID', 'DATE'], ascending=[True, True])\nstarter=starter.sort_values(by=['ID'], ascending=[True])\ndfx =dfx.merge(starter, on=['ID'], how='left')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# calculate the number of days since the beginning of each well. \ndfx['C'] = dfx['DATE'] - dfx['START_DATE']\ndfx['TIME_SINCE_START'] = dfx['C'] / np.timedelta64(1, 'D')\ndfx=dfx.drop(columns=['C'])\ndfx['too_soon'] = np.where((dfx.TIME_SINCE_START < feature_window) , 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\nCreate a running mean, max, min and median for the sensor variables.\n"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "dfx['S5_mean'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S5)\ndfx['S5_median'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).median()) , dfx.S5)\ndfx['S5_max'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).max()) , dfx.S5)\ndfx['S5_min'] = np.where((dfx.too_soon == 0),(dfx['S5'].rolling(min_periods=1, window=feature_window).min()) , dfx.S5)\n\n\ndfx['S13_mean'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S13)\ndfx['S13_median'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).median()) , dfx.S13)\ndfx['S13_max'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).max()) , dfx.S13)\ndfx['S13_min'] = np.where((dfx.too_soon == 0),(dfx['S13'].rolling(min_periods=1, window=feature_window).min()) , dfx.S13)\n\n\ndfx['S15_mean'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S15)\ndfx['S15_median'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).median()) , dfx.S15)\ndfx['S15_max'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).max()) , dfx.S15)\ndfx['S15_min'] = np.where((dfx.too_soon == 0),(dfx['S15'].rolling(min_periods=1, window=feature_window).min()) , dfx.S15)\n\ndfx['S16_mean'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S16)\ndfx['S16_median'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).median()) , dfx.S16)\ndfx['S16_max'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).max()) , dfx.S16)\ndfx['S16_min'] = np.where((dfx.too_soon == 0),(dfx['S16'].rolling(min_periods=1, window=feature_window).min()) , dfx.S16)\n\n\ndfx['S17_mean'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S17)\ndfx['S17_median'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).median()) , dfx.S17)\ndfx['S17_max'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).max()) , dfx.S17)\ndfx['S17_min'] = np.where((dfx.too_soon == 0),(dfx['S17'].rolling(min_periods=1, window=feature_window).min()) , dfx.S17)\n\ndfx['S18_mean'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S18)\ndfx['S18_median'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).median()) , dfx.S18)\ndfx['S18_max'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).max()) , dfx.S18)\ndfx['S18_min'] = np.where((dfx.too_soon == 0),(dfx['S18'].rolling(min_periods=1, window=feature_window).min()) , dfx.S18)\n\n\n\ndfx['S19_mean'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).mean()) , dfx.S19)\ndfx['S19_median'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).median()) , dfx.S19)\ndfx['S19_max'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).max()) , dfx.S19)\ndfx['S19_min'] = np.where((dfx.too_soon == 0),(dfx['S19'].rolling(min_periods=1, window=feature_window).min()) , dfx.S19)\n\n\ndfx.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Another useful transformation is to look for sudden spikes in sensor values. This code creates a value indicating how far the current value is from the immediate norm."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "dfx['S5_chg'] = np.where((dfx.S5_mean == 0),0 , dfx.S5/dfx.S5_mean)\n\n\ndfx['S13_chg'] = np.where((dfx.S13_mean == 0),0 , dfx.S13/dfx.S13_mean)\n\ndfx['S15_chg'] = np.where((dfx.S15_mean==0),0 , dfx.S15/dfx.S15_mean)\ndfx['S16_chg'] = np.where((dfx.S16_mean == 0),0 , dfx.S16/dfx.S16_mean)\ndfx['S17_chg'] = np.where((dfx.S17_mean == 0),0 , dfx.S17/dfx.S17_mean)\ndfx['S18_chg'] = np.where((dfx.S18_mean == 0),0 , dfx.S18/dfx.S18_mean)\ndfx['S19_chg'] = np.where((dfx.S19_mean == 0),0 , dfx.S19/dfx.S19_mean)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#copy the data set to the original name\npd_data=dfx",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 4.0 Dealing with the small number of failures. <a id=\"small\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4.1 Expand the Failure (Target) Window <a id=\"window\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Machines are engineered to last. If something breaks all the time, you won\u2019t buy it, would you?\n\nBecause machines generally last a long time, we typically do not have many examples of failure. This means the data sets we use in PM are almost always unbalanced. \n\nOne way to increase the number of failures is to expand the failure or target window. That is, make the dependent variable, not just the day the equipment failed but the 30 days (or another appropriate interval) leading up to the failure.\n\nIn this example, I use a 28-day target window. We will use the 28 days leading up to a failure as the dependent variable in our model.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "target_window=28",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Sort the data by ID and DATE.  Make sure the index reflects this order."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID', 'DATE'], ascending=[True, True])\npd_data.reset_index(level=0, inplace=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new data frame that contains the failure records.  Rename DATE to FAILURE_DATE"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\ndf_failure_thingy=pd_data[pd_data['EQUIPMENT_FAILURE'] == 1]\n\ndf_failure_thingy=df_failure_thingy[['DATE','ID']]\n\ndf_failure_thingy=df_failure_thingy.rename(index=str, columns={\"DATE\": \"FAILURE_DATE\"})\n\npd_data=pd_data.sort_values(by=['ID'], ascending=[True])\ndf_failure_thingy=df_failure_thingy.sort_values(by=['ID'], ascending=[True])\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the FAILURE_DATE to each ID"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data =pd_data.merge(df_failure_thingy, on=['ID'], how='left')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "For each record calculate the number of days until failure."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\npd_data=pd_data.sort_values(by=['ID','DATE'], ascending=[True, True])\n\npd_data['FAILURE_DATE'] = pd.to_datetime(pd_data['FAILURE_DATE'])\npd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\npd_data['C'] = pd_data['FAILURE_DATE'] - pd_data['DATE']\n\npd_data['TIME_TO_FAILURE'] = pd_data['C'] / np.timedelta64(1, 'D')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Clean up and sort the records by ID and DATE"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data=pd_data.drop(columns=['index'])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID', 'DATE'], ascending=[True, True])\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.reset_index(inplace=True)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new variable, FAILURE_TARGET.  It is equal to 1 if the record proceeds a failure by \"failure_window\" days or less."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data['FAILURE_TARGET'] = np.where(((pd_data.TIME_TO_FAILURE < target_window) & ((pd_data.TIME_TO_FAILURE>=0))), 1, 0)\n\npd_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['FAILURE_TARGET'])['S5'].count()\ntips_summed",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The new field occurs about 4% of the time."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_data['FAILURE_TARGET'].mean()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we have 11,740 target observations. This is better, but the data set is far from balanced. In the next section, we will use SMOTE to increase the number of failures synthetically. However, before we do that, let\u2019s split our data into training, testing, and a validation sample."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4.2 Create the Testing, Training and Validation Groupings <a id=\"groups\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Because we are dealing with a panel data set (cross-sectional time-series), it is better not to take a random sample of all records. Doing so would put the records from one machine in all three sample data sets. To avoid this, we\u2019ll randomly select IDs and place all of the records for each machine in either the training, testing, or validation data set."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "#Get a Unique List of All IDs \n\n\naa=pd_data\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new variable with a random number between 0 and 1"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "np.random.seed(42)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_id['wookie'] = (np.random.randint(0, 10000, pd_id.shape[0]))/10000",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\npd_id=pd_id[['ID', 'wookie']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Give each record a 30% chance of being in the validation, a 35% chance of being in the testing and a 35% chance of being in the training data set\n"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_id['MODELING_GROUP'] = np.where(((pd_id.wookie <= 0.35)), 'TRAINING', np.where(((pd_id.wookie <= 0.65)), 'VALIDATION', 'TESTING'))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many machines fall in each group"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_id.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the Group of each id to each individual record"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data=pd_data.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "pd_data =pd_data.merge(pd_id, on=['ID'], how='inner')\n\npd_data.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many records are in each group."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This is how many failure targets are in each group."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "tips_summed = pd_data.groupby(['MODELING_GROUP'])['FAILURE_TARGET'].sum()\ntips_summed",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for the training data.  We will use this data set to build the model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_training=pd_data[pd_data['MODELING_GROUP'] == 'TRAINING']\ndf_training=df_training.drop(columns=['MODELING_GROUP','C','wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_training.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for the training and testing data sets.  We will use this to tweak our modeling results."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "df_train_test=pd_data[pd_data['MODELING_GROUP'] != 'VALIDATION']\n\ndf_train_test=df_train_test.drop(columns=['wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_train_test.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a separate data frame for all the data. We will use this to validate the model and comapre the accuracy of all groups."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_total=pd_data.drop(columns=['C','wookie','TIME_TO_FAILURE','flipper','START_DATE'])\ndf_total.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4.3 SMOTE the Training Data <a id=\"smote\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Note that we are only balancing the training data set. You may be asking why. Remember that our goal is to build a model the represents reality, right? When we SMOTE the data, we change the failure rate to 50%. This is no where near what we see in the actual machine data. Thus, goodness of fit statistics can be skewed. Because of this, it makes sense to build the model on the SMOTE data, but validate and test it on on the unaltered data. The unaltered data will be a better reflection of what to expect when you deploy the model to production.\n\nDefine the Training features and Target"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "training_features=df_training[['REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','AGE_OF_EQUIPMENT','S15','S17','S13','S5',\n 'S16','S19','S18','S8','S5_mean','S5_median','S5_max','S5_min','S13_mean','S13_median','S13_max','S13_min','S15_mean','S15_median',\n 'S15_max','S15_min','S16_mean','S16_median','S16_max','S16_min','S17_mean','S17_median','S17_max','S17_min','S18_mean','S18_median','S18_max','S18_min','S19_mean','S19_median','S19_max','S19_min',\n 'S5_chg','S13_chg','S15_chg','S16_chg','S17_chg','S18_chg','S19_chg']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "training_target=df_training[['FAILURE_TARGET']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Synthetically Balance the training data sets with a SMOTE algorithm. After we apply the SMOTE algorithm, we will have a balanced data set. 50% Failures and 50% Non-Failures. Note that this takes a while to run."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#uncomment these options if you want to expand the number of rows and columns that appear visually on the screen.\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SMOTENC\n#sm = SMOTE(random_state=12, ratio = 1.0)\nsmx = SMOTENC(random_state=12,  categorical_features=[0, 1, 2, 3])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "x_res, y_res = smx.fit_sample(training_features, training_target.values.ravel())",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert the SMOTE output back to complete data frames with independent and dependent variables.  Examine the results."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Format the Independent Variables"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_x=pd.DataFrame(x_res)\n\ndf_x.columns = [\n 'REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','AGE_OF_EQUIPMENT','S15','S17','S13','S5','S16','S19',\n 'S18','S8','S5_mean','S5_median','S5_max','S5_min','S13_mean','S13_median','S13_max','S13_min','S15_mean','S15_median','S15_max',\n 'S15_min','S16_mean','S16_median','S16_max','S16_min','S17_mean','S17_median','S17_max','S17_min','S18_mean','S18_median','S18_max','S18_min',\n 'S19_mean','S19_median','S19_max','S19_min','S5_chg','S13_chg','S15_chg','S16_chg','S17_chg','S18_chg','S19_chg']\ndf_x.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Format the Dependent Variable"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_y=pd.DataFrame(y_res)\ndf_y.columns = ['FAILURE_TARGET']",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Check that the dependent variable is balanced.  It is."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_y.mean(axis = 0) ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "markdown",
            "source": "Merge the dependent and independent variables post SMOTE into a dataframe"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_balanced = pd.concat([df_y, df_x], axis=1)\ndf_balanced.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 5.0 More data transformation and feature engineering <a id=\"more\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Convert the categorical variables into binary dummy variables. We need to do this because the XGBT model (below) doesn't like categorical fields."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_balanced['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_balanced= pd.concat([df_balanced, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_balanced['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_balanced['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_balanced['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_balanced = pd.concat([df_balanced, df_dv], axis=1)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_train_test['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_train_test= pd.concat([df_train_test, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_train_test['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_train_test['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_train_test['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_train_test = pd.concat([df_train_test, df_dv], axis=1)\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_dv = pd.get_dummies(df_total['REGION_CLUSTER'])\n\ndf_dv=df_dv.rename(columns={\"A\": \"CLUSTER_A\",\"B\":\"CLUSTER_B\",\"C\":\"CLUSTER_C\",\"D\":\"CLUSTER_D\",\"E\":\"CLUSTER_E\",\"F\":\"CLUSTER_F\",\"G\":\"CLUSTER_G\",\"H\":\"CLUSTER_H\"})\n\n\ndf_total= pd.concat([df_total, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_total['MAINTENANCE_VENDOR'])\n\ndf_dv=df_dv.rename(columns={\"I\": \"MV_I\",\"J\":\"MV_J\",\"K\":\"MV_K\",\"L\":\"MV_L\",\"M\":\"MV_M\",\"N\":\"MV_N\",\"O\":\"MV_O\",\"P\":\"MV_P\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)\n\n\n\ndf_dv = pd.get_dummies(df_total['MANUFACTURER'])\n\ndf_dv=df_dv.rename(columns={\"Q\": \"MN_Q\",\"R\":\"MN_R\",\"S\":\"MN_S\",\"T\":\"MN_T\",\"U\":\"MN_U\",\"V\":\"MN_V\",\"W\":\"MN_W\",\"X\":\"MN_X\",\"Y\":\"MN_Y\",\"Z\":\"MN_Z\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)\n\n\ndf_dv = pd.get_dummies(df_total['WELL_GROUP'])\n\ndf_dv=df_dv.rename(columns={1: \"WG_1\",2:\"WG_2\",3:\"WG_3\",4:\"WG_4\",5:\"WG_5\",6:\"WG_6\",7:\"WG_7\",8:\"WG_8\"})\n\n\ndf_total = pd.concat([df_total, df_dv], axis=1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 6.0 Build the model on the balanced training data set <a id=\"build\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Remove the newly redundant categorical variables.  This are now represented by dummy variables.\ndf_balanced=df_balanced.drop(columns=['REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP'])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In the balanced data set, separate the dependent and independent variables to feed to the model development process."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\nfeatures = [x for x in df_balanced.columns if x not in ['FAILURE_TARGET','EQUIPMENT_FAILURE']]  \ndependent=pd.DataFrame(df_balanced['FAILURE_TARGET'])\n\nindependent=df_balanced.drop(columns=['FAILURE_TARGET'])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#make sure everything is numeric for simplicity\nindependent = independent.apply(pd.to_numeric) \ndf_balanced = df_balanced.apply(pd.to_numeric)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define model specs"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import matplotlib.pylab as plt\n%matplotlib inline\n\ndef evaluate_model(alg, train, target, predictors,  early_stopping_rounds=1):\n    \n   \n    #Fit the algorithm on the data\n    alg.fit(train[predictors], target['FAILURE_TARGET'], eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(train[predictors])\n    dtrain_predprob = alg.predict_proba(train[predictors])[:,1]\n    \n    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False) \n    feat_imp.plot(kind='bar', title='Feature Importance', color='g') \n    plt.ylabel('Feature Importance Score')\n        \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Accuracy : %.4g\" % metrics.accuracy_score(target['FAILURE_TARGET'].values, dtrain_predictions))\n    print(\"AUC Score (Balanced): %f\" % metrics.roc_auc_score(target['FAILURE_TARGET'], dtrain_predprob))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We are initializing our model with default model parameters. Note that we could probably improve the results by tweaking the parameters, but we will save that exercise for another day. This step can take a while."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xgb0 = XGBClassifier(\n objective= 'binary:logistic')\n\nevaluate_model(xgb0, independent, dependent,features) ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Using a 50% cut-off on the balanced data, the accuracy is 84% and the AUC score is 91.6%"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now, we will apply the model to the unbalanced training and testing data set."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 7.0 Evaluate model on the unbalanced training and testing data set. <a id=\"score\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This will assign a probability to fail for each record in the unbalanced training data set."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_train_test['P_FAIL']= xgb0.predict_proba(df_train_test[features])[:,1];\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Use a cut-off of .67 to categorize the p-value into a binary variable. If the probability of failing is greater than 67%, the record is a predicted failure. If the chance to fail is less than 67%, the record is a predicted non-failure. Note that determining the best cut-off is a bit art and a bit science. I will reserve a discussion on this for another day, but here are some techniques if you are interested.  \nhttps://medium.com/swlh/determining-a-cut-off-or-threshold-when-working-with-a-binary-dependent-target-variable-7c2342cf2a7c\n\n\nAlso, split the training and testing records into two data frames."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_train_test['Y_FAIL'] = np.where(((df_train_test.P_FAIL <= .67)), 0, 1)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_testing=df_train_test[df_train_test['MODELING_GROUP'] == 'TESTING']",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_training=df_train_test[df_train_test['MODELING_GROUP'] != 'TESTING']",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Build a ROC Curve for Unbalanced Testing Data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fpr, tpr, threshold=metrics.roc_curve(df_testing['FAILURE_TARGET'], df_testing['P_FAIL'])\nroc_auc = metrics.auc(fpr, tpr)\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Build a ROC Curve for Unbalanced Training Data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "fpr, tpr, threshold=metrics.roc_curve(df_training['FAILURE_TARGET'], df_training['P_FAIL'])\nroc_auc = metrics.auc(fpr, tpr)\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "With a cut-off of .67 the unblananced testing data set has an accuracy of 94% and AUC Score of 59%"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Print model report:\nprint(\"Accuracy : %.4g\" % metrics.accuracy_score(df_testing['FAILURE_TARGET'].values, df_testing['Y_FAIL']))\nprint(\"AUC Score (Test): %f\" % metrics.roc_auc_score(df_testing['FAILURE_TARGET'], df_testing['P_FAIL']))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "With a cut-off of .67 the unblananced training data set has an accuracy of 95% and AUC Score of 89%"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Print model report:\nprint(\"Accuracy : %.4g\" % metrics.accuracy_score(df_training['FAILURE_TARGET'].values, df_training['Y_FAIL']))\nprint(\"AUC Score (Train): %f\" % metrics.roc_auc_score(df_training['FAILURE_TARGET'], df_training['P_FAIL']))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Based on the AUC curve, this model kind of stinks, huh? Let's take a look at the testing data with a confusion matrix.\n\nFirst, we will examine ('FAILURE_TARGET') the variable that is '1' if a date is within 28 days of a failure."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a confusion Matrix on the Testing Data"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pd.crosstab(df_testing.Y_FAIL, df_testing.FAILURE_TARGET, dropna=False))\npd.crosstab(df_testing.Y_FAIL, df_testing.FAILURE_TARGET).apply(lambda r: r/r.sum(), axis=1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This confusion matrix doesn\u2019t work, does it? Think about it. \n\nFor example, let\u2019s say that the machine fails on Sunday, and we have failure signals on Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, and Sunday. According to the matrix above, we would register six false positives and one true positive. In reality, we have one signal that occurred on seven consecutive days. These seven days should be counted as one true positive.\n\nNext, we will examine a confusion matrix with the original variable. A \u20181\u2019 appears only on the days where a failure is registered"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(pd.crosstab(df_testing.Y_FAIL, df_testing.EQUIPMENT_FAILURE, dropna=False))\npd.crosstab(df_testing.Y_FAIL, df_testing.EQUIPMENT_FAILURE).apply(lambda r: r/r.sum(), axis=1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This confusion matrix doesn\u2019t work either, does it?\n\nThink about it. A real positive only occurs if a failure happens on the same day as the signal. What if a signal happens on Monday, and it failed on Tuesday? I would count that as a true positive, but the confusion matrix above does not.\n\nSo, we have some cleaning up to do. In the next section, we will build a more realistic confusion matrix.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 8.0 Business Rules and Heuristics <a id=\"bus\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "There is subjectivity when we create business rules and heuristics, just like when you fine-tune a model. For this reason, make sure you do your tweaking on the training data set and validate the results on the testing and validation data sets. This gives you the best chance of creating a result that will be reflective of an implementation.\nFirst, we will create a business rule that eliminates signals in \u201cbunches.\u201d For example, if there is a signal on Monday, Tuesday, and Wednesday, you likely don\u2019t have three different problems. You more than probably have one problem identified on three consecutive days.\n\nTo reduce the repetitive signals, we will create a business rule. This business rule will prohibit more than one signal every 90 days.\n\nEssentially we are saying that a failure signal means the equipment will fail in the next 90 days. Determining the window depends on the frequency of failure. If the equipment fails ten times a year, a 90-day window isn\u2019t very useful. On the other hand, if the equipment fails once every five years, a three-month window is meaningful. Remember, the machines for this exercise are designed to last 4 to 6 years.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "forecast_window=90",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort the data by id and date.\nxx=df_training\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True, True])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Because our data is a panel, we must define the forecast window by machine ID. We want to prevent signals from one machine from \"bleeding\" into another machine. \n\nIn other words, if a failure signal occurs on the last day a machine appears in the data, we don't want that signal to effect the subsequent machine.\n\nThe following code ensures that each forecast window is specific to each machine."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create a unique list of machines\naa=xx\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#label each machine with a sequential number\npd_id=pd_id.reset_index(drop=True)\npd_id=pd_id.reset_index(drop=False)\npd_id=pd_id.rename(columns={\"index\": \"SCOOBYDOO\"})\npd_id['SCOOBYDOO']=pd_id['SCOOBYDOO']+1\npd_id.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#grab the max number of machines +1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "column = pd_id[\"SCOOBYDOO\"]\nmax_value = column.max()+1\nmax_value",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#append sequential number to main file\nxx=xx.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])\nxx =xx.merge(pd_id, on=['ID'], how='inner')\nxx.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\n\n\n#sort data\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True,True])\n\n#reset index\nxx=xx.reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create a null dataframe for the next step\ndf_fred=xx\ndf_fred['Y_FAIL_sumxx']=0\ndf_fred=df_fred[df_fred['SCOOBYDOO'] == max_value+1]\ndf_fred.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This step assigns a new failure indicator that incorporates the forecast window.  Note, this calulation occurs at a machine level.  This keeps a signal from one machine effecting another machine."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for x in range(max_value):\n        dffx=xx[xx['SCOOBYDOO'] ==x]\n        dff=dffx.copy()\n        dff['Y_FAIL_sumxx'] =(dff['Y_FAIL'].rolling(min_periods=1, window=(forecast_window)).sum())\n        df_fred= pd.concat([df_fred,dff])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dff=df_fred\ndff.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "xx=dff",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# if a signal has occured in the last Z days, the signal is 0.\nxx['Y_FAILZ']=np.where((xx.Y_FAIL_sumxx>1), 0, xx.Y_FAIL)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now, let's examine a confusion matrix with our new failure indicator."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "print(pd.crosstab(xx.Y_FAILZ, xx.EQUIPMENT_FAILURE, dropna=False))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "This confusion matrix is more realistic, but we still have more work to do.\n\nA true positive occurs if a failure signal and an actual failure occur on the same day. For example, if a signal appears on Friday and the failure occurs on Saturday, this should be considered a true positive. The confusion matrix above currently counts this as a false positive.\n\nNow, we continue to apply business rules to make the results more realistic. First, we will create a unique id for each signal. This unique id will help us classify them as a true or false prediction of failure."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#sort the data by id and date.\n\nxx=xx.sort_values(by=['ID','DATE'], ascending=[True, True])\n\n#xx['bootie']=1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "#create signal id with the cumsum function.\nxx['SIGNAL_ID'] = xx['Y_FAILZ'].cumsum()\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we will pull the records with a signal into a different data frame. \n\nHere we will create a new field that identifies the date of each signal (SIGNAL_DATE). \n\nAlso, we will identify the ID Associated with each signal (ID_OF_SIGNAL)\n"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\n\ndf_signals=xx[xx['Y_FAILZ'] == 1]\ndf_signal_date=df_signals[['SIGNAL_ID','DATE','ID']]\ndf_signal_date=df_signal_date.rename(index=str, columns={\"DATE\": \"SIGNAL_DATE\"})\ndf_signal_date=df_signal_date.rename(index=str, columns={\"ID\": \"ID_OF_SIGNAL\"})\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We have a total of 302 signals.  Now each has a unique id.  Note that is still too many.  Below we will apply more heuristics to decrease the number of signals."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_signal_date.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Append the new fields to the working data frame."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xx =xx.merge(df_signal_date, on=['SIGNAL_ID'], how='outer')\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Keep the fields we need to use going forward."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xx=xx[['DATE', 'ID', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET','FAILURE_DATE',\n       'P_FAIL', 'Y_FAILZ','SIGNAL_ID',\n       'SIGNAL_DATE','ID_OF_SIGNAL']]\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": " Create a field called \"Warning\" that indicates the time from signal to failure."
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "\nxx['C'] = xx['FAILURE_DATE'] - xx['SIGNAL_DATE']\nxx['WARNING'] = xx['C'] / np.timedelta64(1, 'D')\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Replace nan with 9999.  \n\nxx['WARNING'].fillna(9999, inplace=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##  9.0 Define a True Positive, True Negative, False Positive and False Negative <a id=\"tp\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Defining a false positive, false negative, true positive, and true negative is one of the more essential steps in predictive maintenance models.  The problem's context drives these definitions, and there is no one size fits all approach. \n\nMy definition makes sense here but is unique to this specific business problem.\n\nA true positive occurs if and only if the machine fails, and there was a signal within the last 90 days. Also, we have to ensure that the signal id belongs to the Well ID. Note that this prohibits a signal from another machine from being applied to the machine in question.\n\nA false negative occurs if and only if the machine fails, and it is not a true positive.\n\nA False Positive occurs if there is a failure signal, and a failure does not happen in the next 90 days. Also, if a signal occurs after the failure, this is a false positive. We also have to ensure that the signal ID belongs to the machine ID. Note that this prohibits a signal from another machine from being applied to the machine in question.\n\nIf an observation is not a False Positive, a False Negative, or a True Positive, it is a True Negative.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a true positive\nxx['TRUE_POSITIVE'] = np.where(((xx.EQUIPMENT_FAILURE == 1) & (xx.WARNING<=forecast_window) &(xx.WARNING>=0) & (xx.ID_OF_SIGNAL==xx.ID)), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false negative\nxx['FALSE_NEGATIVE'] = np.where((xx.TRUE_POSITIVE==0) & (xx.EQUIPMENT_FAILURE==1), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# define a false positive\nxx['BAD_S']=np.where((xx.WARNING<0) | (xx.WARNING>=forecast_window), 1, 0)\n\nxx['FALSE_POSITIVE'] = np.where(((xx.Y_FAILZ == 1) & (xx.BAD_S==1) & (xx.ID_OF_SIGNAL==xx.ID)), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xx['bootie']=1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xx['MODELING_GROUP']='TRAINING'",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": false
            },
            "cell_type": "markdown",
            "source": "Create the final Cross-Tab"
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "xx['CATEGORY']=np.where((xx.FALSE_POSITIVE==1),'FALSE_POSITIVE',\n                                      (np.where((xx.FALSE_NEGATIVE==1),'FALSE_NEGATIVE',\n                                                (np.where((xx.TRUE_POSITIVE==1),'TRUE_POSITIVE','TRUE_NEGATIVE')))))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "table = pd.pivot_table(xx, values=['bootie'], index=['MODELING_GROUP'],columns=['CATEGORY'], aggfunc=np.sum)\ntable",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Using the previously described definitions of a false positive, false negative, true positive and true negative in the training data set there are:\n    \n    41 False Negatives\n    107 False Positives\n    106361 True Negatives and\n    105 True Postives.\n    \n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## 10.0 Apply Model and Heuristics the Testing and Validation Data Sets. <a id=\"apply\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Predict the probability of failure for all records."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_total['P_FAIL']= xgb0.predict_proba(df_total[features])[:,1];",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a predicted failure indicator based on a cut-off of .67."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_total['Y_FAIL'] = np.where(((df_total.P_FAIL <= .67)), 0, 1)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=df_total\n\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Ensure that failure indicator occurs only once every 120 days."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "aa=yy\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pd_id=pd_id.reset_index(drop=True)\npd_id=pd_id.reset_index(drop=False)\npd_id=pd_id.rename(columns={\"index\": \"SCOOBYDOO\"})\npd_id['SCOOBYDOO']=pd_id['SCOOBYDOO']+1\npd_id.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ncolumn = pd_id[\"SCOOBYDOO\"]\nmax_value = column.max()+1\nmax_value",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "yy=yy.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])\nyy =yy.merge(pd_id, on=['ID'], how='inner')\nyy.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=yy.sort_values(by=['ID','DATE'], ascending=[True,True])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=yy.reset_index(drop=True)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df_fred=yy\ndf_fred['Y_FAIL_sumxx']=0\ndf_fred=df_fred[df_fred['SCOOBYDOO'] == max_value+1]\ndf_fred.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "for x in range(max_value):\n        dffx=yy[yy['SCOOBYDOO'] ==x]\n        dff=dffx.copy()\n        dff['Y_FAIL_sumxx'] =(dff['Y_FAIL'].rolling(min_periods=1, window=(forecast_window)).sum())\n        df_fred= pd.concat([df_fred,dff])\n        ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "dff=df_fred\ndff.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=dff",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['Y_FAILZ']=np.where((yy.Y_FAIL_sumxx>1), 0, yy.Y_FAIL)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create the WARNING Field"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy=yy.sort_values(by=['ID','DATE'], ascending=[True, True])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create a signal id\nyy['SIGNAL_ID'] = yy['Y_FAILZ'].cumsum()\n\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#create the signal date and ID_OF_SIGNAL\n\nyy_signals=yy[yy['Y_FAILZ'] == 1]\nyy_signal_date=yy_signals[['SIGNAL_ID','DATE','ID']]\nyy_signal_date=yy_signal_date.rename(index=str, columns={\"DATE\": \"SIGNAL_DATE\"})\nyy_signal_date=yy_signal_date.rename(index=str, columns={\"ID\": \"ID_OF_SIGNAL\"})",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#merge the two data frames back into one.\n\nyy =yy.merge(yy_signal_date, on=['SIGNAL_ID'], how='outer')\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Keep on the fields we need\nyy=yy[['DATE', 'ID', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET','FAILURE_DATE','MODELING_GROUP',\n       'P_FAIL', 'Y_FAILZ','SIGNAL_ID',\n       'SIGNAL_DATE','ID_OF_SIGNAL']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Calculate the warning time between each failure date and signal date.\nyy['C'] = yy['FAILURE_DATE'] - yy['SIGNAL_DATE']\nyy['WARNING'] = yy['C'] / np.timedelta64(1, 'D')",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define True Positives, True Negatives, False Positives and False Negatives."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['WARNING'].fillna(9999, inplace=True)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a true positive\nyy['TRUE_POSITIVE'] = np.where(((yy.EQUIPMENT_FAILURE == 1) & (yy.WARNING<=forecast_window) &(yy.WARNING>=0) & (yy.ID_OF_SIGNAL==yy.ID)), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false negative\nyy['FALSE_NEGATIVE'] = np.where((yy.TRUE_POSITIVE==0) & (yy.EQUIPMENT_FAILURE==1), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define a false positive\nyy['BAD_S']=np.where((yy.WARNING<0) | (yy.WARNING>=forecast_window), 1, 0)\n\nyy['FALSE_POSITIVE'] = np.where(((yy.Y_FAILZ == 1) & (yy.BAD_S==1) & (yy.ID_OF_SIGNAL==yy.ID)), 1, 0)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['bootie']=1",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['CATEGORY']=np.where((yy.FALSE_POSITIVE==1),'FALSE_POSITIVE',\n                                      (np.where((yy.FALSE_NEGATIVE==1),'FALSE_NEGATIVE',\n                                                (np.where((yy.TRUE_POSITIVE==1),'TRUE_POSITIVE','TRUE_NEGATIVE')))))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Define metrics for the Testing, Training and Validation Data sets."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "table = pd.pivot_table(yy, values=['bootie'], index=['MODELING_GROUP'],columns=['CATEGORY'], aggfunc=np.sum)\ntable",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Remember when I introduced the use case I presented this chart.\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://miro.medium.com/max/4800/1*5Ar2n3ZHMwVeOhgXI_dm0w.png\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "A false positive is \u201cUnnecessary Maintenance.\u201d \nA true positive is a \u201cTimely and Appropriate Maintenance.\u201d \nA false negative is \u201cMachine Runs to Failure.\u201d \n\nThis means that a false positive costs $1,500.   \n\nA false negative costs $30,000.   \n\nA true positive costs $7,500. \n\nA true negative has no cost because no action is taken.\n\nNow we can calculate the total cost."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "yy['TOTAL_COST']=yy.FALSE_NEGATIVE*30000+yy.FALSE_POSITIVE*1500+yy.TRUE_POSITIVE*7500",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Aggregate the costs by modeling group"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "\ntable = pd.pivot_table(yy, values=['TOTAL_COST'],index=['MODELING_GROUP'], aggfunc=np.sum)\ntable",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the number of machines per modelling group"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells=yy[['ID','MODELING_GROUP']]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells=wells.drop_duplicates(subset='ID')\n\nwells.shape",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells = wells.groupby(['MODELING_GROUP'])['ID'].count()\nwells=pd.DataFrame(wells)\nwells=wells.rename(columns={\"ID\": \"WELLS\"})",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "wells",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Merge the total costs and total machines into one dataframe"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "tc = yy.groupby(['MODELING_GROUP'])['TOTAL_COST'].sum()\ntc=pd.DataFrame(tc)\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Calculate the average cost per machine"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ac =tc.merge(wells, on=['MODELING_GROUP'], how='inner')\n",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ac['AVERAGE_COST']=ac.TOTAL_COST/ac.WELLS\nac['LIFT']=28000-ac.AVERAGE_COST",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ac",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "##  11.0 Conclusions <a id=\"conc\"></a>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "It currently costs the firm about 28,000 dollars per machine in the current data set. By deploying a PM solution, we can lower those costs to between 22,000 and 23,000 dollars. This equates to a savings of about 4,500 per machine. For all 419 machines, this is a total savings of approximately 1,885,000 dollars.\n\nNot too shabby.\n\nOne final note. There are many judgments I made that work for this example but may not work for you. Unfortunately, there is no \u201cone size fits all\u201d solution for any data science problem.\n\nNonetheless, this exercise should give you a useful reference as you approach these types of problems in the future.\n\nAs far as the next steps, I would encourage you to see if you can improve the solution by optimizing the model. Maybe incorporate some hyper-parameter optimization or even try a different model. Let me know how it turns out!\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Author\n\n\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\n**Shad Griffin**, is a Data Scientist at the IBM Global Solution Center in Dallas, Texas"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<hr>\nCopyright &copy; IBM Corp. 2020. This notebook and its source code are released under the terms of the MIT License.\n\n"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}